{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n.anokhin/Projects/virtualenv/recsys-course/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import lightfm\n",
    "import lightfm.data as ld\n",
    "import lightfm.evaluation as lv\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "import tensorboardX as tb\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/n.anokhin/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>latency</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>experiments</th>\n",
       "      <th>rnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>next</td>\n",
       "      <td>2024-03-04 09:06:00.999</td>\n",
       "      <td>2620</td>\n",
       "      <td>32065</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>32069.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.721852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>next</td>\n",
       "      <td>2024-03-04 09:06:01.057</td>\n",
       "      <td>5687</td>\n",
       "      <td>32024</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>37337.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.966441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next</td>\n",
       "      <td>2024-03-04 09:06:01.078</td>\n",
       "      <td>7957</td>\n",
       "      <td>14080</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>5540.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.289049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>next</td>\n",
       "      <td>2024-03-04 09:06:01.092</td>\n",
       "      <td>7957</td>\n",
       "      <td>10027</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>492.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.171346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>last</td>\n",
       "      <td>2024-03-04 09:06:01.111</td>\n",
       "      <td>7957</td>\n",
       "      <td>14271</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.371618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message               timestamp  user  track  time   latency  \\\n",
       "0    next 2024-03-04 09:06:00.999  2620  32065  0.00  0.001914   \n",
       "1    next 2024-03-04 09:06:01.057  5687  32024  0.80  0.001389   \n",
       "2    next 2024-03-04 09:06:01.078  7957  14080  0.80  0.001621   \n",
       "3    next 2024-03-04 09:06:01.092  7957  10027  0.41  0.000477   \n",
       "4    last 2024-03-04 09:06:01.111  7957  14271  0.01  0.000207   \n",
       "\n",
       "   recommendation experiments       rnd  \n",
       "0         32069.0          {}  0.721852  \n",
       "1         37337.0          {}  0.966441  \n",
       "2          5540.0          {}  0.289049  \n",
       "3           492.0          {}  0.171346  \n",
       "4             NaN          {}  0.371618  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([\n",
    "    pd.read_json(data_path, lines=True) \n",
    "    for data_path \n",
    "    in glob.glob(DATA_DIR + \"/data/*/data.json\")\n",
    "])\n",
    "data[\"rnd\"] = np.random.random(len(data))\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = data[data[\"time\"] > 0.8].copy()\n",
    "positives[\"test\"] = np.random.random(len(positives)) >= 0.7\n",
    "positives.drop_duplicates([\"user\", \"track\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = positives[~positives[\"test\"]].groupby(\"user\").size()\n",
    "users = set(user_counts[user_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = positives[~positives[\"test\"]].groupby(\"track\").size()\n",
    "tracks = set(track_counts[track_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9750, 4571)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users), len(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71514, 28207)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = positives[~positives[\"test\"] & positives[\"user\"].isin(users) & positives[\"track\"].isin(tracks)]\n",
    "test_data = positives[positives[\"test\"] & positives[\"user\"].isin(users) & positives[\"track\"].isin(tracks)]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ld.Dataset()\n",
    "dataset.fit(users, tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, _ = dataset.build_interactions(train_data[[\"user\", \"track\"]].itertuples(index=False, name=None))\n",
    "test_interactions, _ = dataset.build_interactions(test_data[[\"user\", \"track\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(\n",
    "    epochs=1, \n",
    "    at=10,\n",
    "    loss=\"warp\",\n",
    "    no_components=30,\n",
    "    learning_rate=0.01, \n",
    "    max_sampled=10,\n",
    "    user_alpha=0.0, \n",
    "    item_alpha=0.0, \n",
    "    threads=30, \n",
    "    verbose=False,\n",
    "    patience=3,\n",
    "    epsilon=1e-6,\n",
    "):\n",
    "    model = lightfm.LightFM(\n",
    "        no_components=no_components,\n",
    "        loss=loss,\n",
    "        learning_rate=learning_rate,\n",
    "        max_sampled=max_sampled,\n",
    "        user_alpha=user_alpha,\n",
    "        item_alpha=item_alpha,\n",
    "    )\n",
    "\n",
    "    precisions_at = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model = model.fit_partial(train_interactions, num_threads=threads)\n",
    "        \n",
    "        precision_at = lv.precision_at_k(model, test_interactions, train_interactions=train_interactions, k=at, num_threads=threads)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{epoch}:\\t{np.mean(precision_at)} +/- {ss.sem(precision_at) * 1.96}\")\n",
    "            \n",
    "        precisions_at.append(np.mean(precision_at))\n",
    "            \n",
    "        if epoch > patience and all([precisions_at[-j] - precisions_at[-patience-1] < epsilon for j in range(1, patience + 1)]):\n",
    "            if verbose:\n",
    "                print(\"Early stopiing!\")\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"No early stopiing happened: increase epochs maybe?\")\n",
    "        \n",
    "    return model, precisions_at\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    loss = trial.suggest_categorical(\"loss\", [\"warp\", \"bpr\"])\n",
    "    no_components = trial.suggest_categorical(\"no_components\", [10, 30, 50])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.0001, 0.001, 0.01])\n",
    "    max_sampled = trial.suggest_categorical(\"max_sampled\", [10, 20, 50, 100])\n",
    "    user_alpha = trial.suggest_categorical(\"user_alpha\", [0.0, 0.0001])\n",
    "    item_alpha = trial.suggest_categorical(\"item_alpha\", [0.0, 0.0001])\n",
    "    \n",
    "    model, precisions_at = fit_model(\n",
    "        epochs=5, \n",
    "        at=10,\n",
    "        loss=loss,\n",
    "        no_components=no_components, \n",
    "        learning_rate=learning_rate, \n",
    "        max_sampled=max_sampled, \n",
    "        user_alpha=user_alpha, \n",
    "        item_alpha=item_alpha,\n",
    "    )\n",
    "    \n",
    "    return precisions_at[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-03-04 12:38:47,280]\u001b[0m A new study created in memory with name: no-name-05946645-dba5-4e3e-bc36-f93a7894d3a8\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:38:57,600]\u001b[0m Trial 0 finished with value: 0.018938032910227776 and parameters: {'loss': 'warp', 'no_components': 30, 'learning_rate': 0.001, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 0 with value: 0.018938032910227776.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:39:06,465]\u001b[0m Trial 1 finished with value: 0.019117647781968117 and parameters: {'loss': 'warp', 'no_components': 10, 'learning_rate': 0.01, 'max_sampled': 50, 'user_alpha': 0.0001, 'item_alpha': 0.0}. Best is trial 1 with value: 0.019117647781968117.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:39:17,553]\u001b[0m Trial 2 finished with value: 0.019196227192878723 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:39:29,042]\u001b[0m Trial 3 finished with value: 0.019027840346097946 and parameters: {'loss': 'warp', 'no_components': 30, 'learning_rate': 0.01, 'max_sampled': 20, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:39:41,013]\u001b[0m Trial 4 finished with value: 0.00900314375758171 and parameters: {'loss': 'bpr', 'no_components': 30, 'learning_rate': 0.001, 'max_sampled': 20, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:39:51,170]\u001b[0m Trial 5 finished with value: 0.013987427577376366 and parameters: {'loss': 'warp', 'no_components': 10, 'learning_rate': 0.0001, 'max_sampled': 50, 'user_alpha': 0.0001, 'item_alpha': 0.0}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:02,256]\u001b[0m Trial 6 finished with value: 0.01835428737103939 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.0001, 'max_sampled': 10, 'user_alpha': 0.0001, 'item_alpha': 0.0}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:13,110]\u001b[0m Trial 7 finished with value: 0.018578805029392242 and parameters: {'loss': 'warp', 'no_components': 30, 'learning_rate': 0.0001, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:24,429]\u001b[0m Trial 8 finished with value: 0.0069488100707530975 and parameters: {'loss': 'bpr', 'no_components': 30, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0001, 'item_alpha': 0.0}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:35,963]\u001b[0m Trial 9 finished with value: 0.0083071393892169 and parameters: {'loss': 'bpr', 'no_components': 30, 'learning_rate': 0.001, 'max_sampled': 50, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:47,313]\u001b[0m Trial 10 finished with value: 0.0037157610058784485 and parameters: {'loss': 'bpr', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 10, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:40:57,007]\u001b[0m Trial 11 finished with value: 0.01892680861055851 and parameters: {'loss': 'warp', 'no_components': 10, 'learning_rate': 0.01, 'max_sampled': 50, 'user_alpha': 0.0, 'item_alpha': 0.0}. Best is trial 2 with value: 0.019196227192878723.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:41:07,113]\u001b[0m Trial 12 finished with value: 0.01929726079106331 and parameters: {'loss': 'warp', 'no_components': 10, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 12 with value: 0.01929726079106331.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:41:19,060]\u001b[0m Trial 13 finished with value: 0.018982937559485435 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 12 with value: 0.01929726079106331.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:41:30,922]\u001b[0m Trial 14 finished with value: 0.02011674828827381 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 14 with value: 0.02011674828827381.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:41:41,127]\u001b[0m Trial 15 finished with value: 0.019241131842136383 and parameters: {'loss': 'warp', 'no_components': 10, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 14 with value: 0.02011674828827381.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:41:53,006]\u001b[0m Trial 16 finished with value: 0.020318815484642982 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:03,871]\u001b[0m Trial 17 finished with value: 0.02002694271504879 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:15,220]\u001b[0m Trial 18 finished with value: 0.0050516389310359955 and parameters: {'loss': 'bpr', 'no_components': 50, 'learning_rate': 0.001, 'max_sampled': 20, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:25,796]\u001b[0m Trial 19 finished with value: 0.018343063071370125 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.0001, 'max_sampled': 10, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:37,227]\u001b[0m Trial 20 finished with value: 0.019836103543639183 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:47,842]\u001b[0m Trial 21 finished with value: 0.02000449039041996 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:42:58,394]\u001b[0m Trial 22 finished with value: 0.01998203806579113 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:43:09,052]\u001b[0m Trial 23 finished with value: 0.019420744851231575 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 16 with value: 0.020318815484642982.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:43:19,449]\u001b[0m Trial 24 finished with value: 0.020408622920513153 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:43:29,834]\u001b[0m Trial 25 finished with value: 0.019308488816022873 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:43:40,505]\u001b[0m Trial 26 finished with value: 0.0034351146314293146 and parameters: {'loss': 'bpr', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:43:50,997]\u001b[0m Trial 27 finished with value: 0.019465649500489235 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.01, 'max_sampled': 10, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:44:01,671]\u001b[0m Trial 28 finished with value: 0.018915580585598946 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.0001, 'max_sampled': 20, 'user_alpha': 0.0001, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n",
      "\u001b[32m[I 2024-03-04 12:44:12,170]\u001b[0m Trial 29 finished with value: 0.018758419901132584 and parameters: {'loss': 'warp', 'no_components': 50, 'learning_rate': 0.001, 'max_sampled': 100, 'user_alpha': 0.0, 'item_alpha': 0.0001}. Best is trial 24 with value: 0.020408622920513153.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'loss': 'warp',\n",
    "    'no_components': 50,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_sampled': 100,\n",
    "    'user_alpha': 0.0,\n",
    "    'item_alpha': 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t0.01876964420080185 +/- 0.0010069465027825956\n",
      "1:\t0.018735969439148903 +/- 0.0010108157489557086\n",
      "2:\t0.019050292670726776 +/- 0.0010178373302895138\n",
      "3:\t0.019140098243951797 +/- 0.0010204371480820487\n",
      "4:\t0.019735068082809448 +/- 0.0010346662109506782\n",
      "5:\t0.02030758745968342 +/- 0.0010496671890110566\n",
      "6:\t0.020745398476719856 +/- 0.0010677292154084887\n",
      "7:\t0.02147507853806019 +/- 0.001098915502023381\n",
      "8:\t0.02218230813741684 +/- 0.0011292277559827935\n",
      "9:\t0.022563988342881203 +/- 0.0011426087797321654\n",
      "10:\t0.023080378770828247 +/- 0.0011542035988451082\n",
      "11:\t0.02381005883216858 +/- 0.001181262405882392\n",
      "12:\t0.02442748099565506 +/- 0.001197235820699664\n",
      "13:\t0.02488774061203003 +/- 0.0012102638429437294\n",
      "14:\t0.025213293731212616 +/- 0.0012195238854995482\n",
      "15:\t0.02559497207403183 +/- 0.0012287642781797703\n",
      "16:\t0.026021553203463554 +/- 0.0012409943916958644\n",
      "17:\t0.026459364220499992 +/- 0.0012519737983663977\n",
      "18:\t0.02662775106728077 +/- 0.0012552639147414115\n",
      "19:\t0.027099236845970154 +/- 0.0012704910210945824\n",
      "20:\t0.027436016127467155 +/- 0.0012704223238917088\n",
      "21:\t0.02790749818086624 +/- 0.0012785437567269262\n",
      "22:\t0.028446340933442116 +/- 0.0012896573859728939\n",
      "23:\t0.028929051011800766 +/- 0.001302048566579509\n",
      "24:\t0.029220927506685257 +/- 0.0013092577500720625\n",
      "25:\t0.02949034795165062 +/- 0.0013169841739907567\n",
      "26:\t0.030029186978936195 +/- 0.0013249434566714436\n",
      "27:\t0.0303659625351429 +/- 0.0013296639137941272\n",
      "28:\t0.030848678201436996 +/- 0.001339581840373862\n",
      "29:\t0.03162326291203499 +/- 0.0013532278279969302\n",
      "30:\t0.0320049412548542 +/- 0.0013579365261389416\n",
      "31:\t0.03251010924577713 +/- 0.0013696466142071565\n",
      "32:\t0.0327458493411541 +/- 0.001373757925186341\n",
      "33:\t0.03336326777935028 +/- 0.001385801132799121\n",
      "34:\t0.03391333669424057 +/- 0.0013945143827536891\n",
      "35:\t0.03432869166135788 +/- 0.0014003609169991524\n",
      "36:\t0.03487875685095787 +/- 0.0014136248924738084\n",
      "37:\t0.03520430997014046 +/- 0.0014175028805207106\n",
      "38:\t0.03565334901213646 +/- 0.0014232392516840883\n",
      "39:\t0.03620341420173645 +/- 0.0014293140029886472\n",
      "40:\t0.03664122149348259 +/- 0.0014385304135372356\n",
      "41:\t0.03707902878522873 +/- 0.0014446178521630461\n",
      "42:\t0.03752806782722473 +/- 0.0014523322076542085\n",
      "43:\t0.0380220040678978 +/- 0.001459773785738465\n",
      "44:\t0.038482263684272766 +/- 0.0014696298229462416\n",
      "45:\t0.03890884667634964 +/- 0.0014713735560011646\n",
      "46:\t0.039515040814876556 +/- 0.0014805016194712826\n",
      "47:\t0.04000898450613022 +/- 0.0014891443155418181\n",
      "48:\t0.04041311517357826 +/- 0.0014974200076366417\n",
      "49:\t0.04091827571392059 +/- 0.0015042594021317448\n",
      "50:\t0.0413673110306263 +/- 0.0015102159447358638\n",
      "51:\t0.041984736919403076 +/- 0.0015180751213574083\n",
      "52:\t0.042287833988666534 +/- 0.0015206636443395609\n",
      "53:\t0.04275932535529137 +/- 0.0015289639374597376\n",
      "54:\t0.04335429146885872 +/- 0.001533605640356604\n",
      "55:\t0.04372474178671837 +/- 0.0015402626159278603\n",
      "56:\t0.044162552803754807 +/- 0.0015469630687829172\n",
      "57:\t0.04458913579583168 +/- 0.0015520055053632133\n",
      "58:\t0.044735074043273926 +/- 0.0015553380933197335\n",
      "59:\t0.0451616533100605 +/- 0.0015609065895616744\n",
      "60:\t0.045565783977508545 +/- 0.0015617342051881856\n",
      "61:\t0.04598114639520645 +/- 0.001563458288367512\n",
      "62:\t0.046273015439510345 +/- 0.0015662450120633607\n",
      "63:\t0.04672205075621605 +/- 0.0015719228977702378\n",
      "64:\t0.04699147120118141 +/- 0.0015770751879857596\n",
      "65:\t0.04750785976648331 +/- 0.0015835901274483717\n",
      "66:\t0.047968119382858276 +/- 0.0015869276665546486\n",
      "67:\t0.04855186492204666 +/- 0.0015890329882652374\n",
      "68:\t0.04903457686305046 +/- 0.0015967894285293313\n",
      "69:\t0.04937135428190231 +/- 0.001600798776768215\n",
      "70:\t0.049663227051496506 +/- 0.0016002317153976477\n",
      "71:\t0.05013471469283104 +/- 0.0016053799828039921\n",
      "72:\t0.050583746284246445 +/- 0.0016122585223268587\n",
      "73:\t0.0508868470788002 +/- 0.0016154988951191612\n",
      "74:\t0.05130220204591751 +/- 0.0016234501321814939\n",
      "75:\t0.0516277514398098 +/- 0.0016266009201078868\n",
      "76:\t0.05212169140577316 +/- 0.0016352621829900098\n",
      "77:\t0.052503373473882675 +/- 0.001636213422637008\n",
      "78:\t0.052896276116371155 +/- 0.001641842261016608\n",
      "79:\t0.05336776375770569 +/- 0.0016485182675697412\n",
      "80:\t0.05382801964879036 +/- 0.0016524858404825529\n",
      "81:\t0.05424337834119797 +/- 0.0016584835395190242\n",
      "82:\t0.054658737033605576 +/- 0.0016615031219768656\n",
      "83:\t0.055029187351465225 +/- 0.0016659849955706501\n",
      "84:\t0.05554557964205742 +/- 0.0016731098547939104\n",
      "85:\t0.0559384860098362 +/- 0.001674553424394836\n",
      "86:\t0.056331388652324677 +/- 0.00167768827580795\n",
      "87:\t0.05669061839580536 +/- 0.001684288777327294\n",
      "88:\t0.05708352476358414 +/- 0.0016910563801509255\n",
      "89:\t0.057409074157476425 +/- 0.001694459676714908\n",
      "90:\t0.05770094320178032 +/- 0.0016981804657570363\n",
      "91:\t0.058071400970220566 +/- 0.0017042703799577254\n",
      "92:\t0.058464307337999344 +/- 0.001708556373689262\n",
      "93:\t0.05894701927900314 +/- 0.0017111775433151224\n",
      "94:\t0.0592837929725647 +/- 0.0017143622156726628\n",
      "95:\t0.05968792364001274 +/- 0.0017190398144052651\n",
      "96:\t0.06000225245952606 +/- 0.0017258544531515848\n",
      "97:\t0.06054109334945679 +/- 0.0017306366449227964\n",
      "98:\t0.060799285769462585 +/- 0.0017310690969093545\n",
      "99:\t0.06103503331542015 +/- 0.0017335027417381816\n",
      "100:\t0.06148406118154526 +/- 0.001742277571617848\n",
      "101:\t0.06168612465262413 +/- 0.001742809510769829\n",
      "102:\t0.06210148334503174 +/- 0.0017471377439977273\n",
      "103:\t0.062292322516441345 +/- 0.0017496099149605982\n",
      "104:\t0.06267400830984116 +/- 0.0017569984229084009\n",
      "105:\t0.06308935582637787 +/- 0.0017581647281229534\n",
      "106:\t0.0633363276720047 +/- 0.001763414803546169\n",
      "107:\t0.06379659473896027 +/- 0.0017684699274477169\n",
      "108:\t0.06396497786045074 +/- 0.0017678997716085517\n",
      "109:\t0.0642680823802948 +/- 0.001772601043025928\n",
      "110:\t0.06459363549947739 +/- 0.0017741886601400862\n",
      "111:\t0.0650426521897316 +/- 0.0017777524049008705\n",
      "112:\t0.06537943333387375 +/- 0.0017808646666932196\n",
      "113:\t0.0657162144780159 +/- 0.0017834008931560674\n",
      "114:\t0.06582847237586975 +/- 0.0017843298526291603\n",
      "115:\t0.06596318632364273 +/- 0.001783540763136693\n",
      "116:\t0.06621014326810837 +/- 0.0017869205417393316\n",
      "117:\t0.0664234459400177 +/- 0.0017914935474333245\n",
      "118:\t0.06656938046216965 +/- 0.0017879376935674648\n",
      "119:\t0.06688370555639267 +/- 0.0017934308394990466\n",
      "120:\t0.06720925122499466 +/- 0.001797760310514384\n",
      "121:\t0.06737764924764633 +/- 0.0018016361324332676\n",
      "122:\t0.06759093701839447 +/- 0.0018034298411560468\n",
      "123:\t0.0678379014134407 +/- 0.0018037258270774369\n",
      "124:\t0.06796139478683472 +/- 0.0018061484865427415\n",
      "125:\t0.06821957975625992 +/- 0.001807445223608696\n",
      "126:\t0.0683542937040329 +/- 0.0018081965605842689\n",
      "127:\t0.06870229542255402 +/- 0.0018098708228191686\n",
      "128:\t0.06893803924322128 +/- 0.0018112209394684372\n",
      "129:\t0.0690951943397522 +/- 0.0018121129200417852\n",
      "130:\t0.06918501108884811 +/- 0.0018109017450325627\n",
      "131:\t0.06944319605827332 +/- 0.0018113184152292715\n",
      "132:\t0.06975752115249634 +/- 0.0018151931540841457\n",
      "133:\t0.0698024332523346 +/- 0.0018141817270229184\n",
      "134:\t0.07013920694589615 +/- 0.001817650162150887\n",
      "135:\t0.0702851414680481 +/- 0.0018209428314624944\n",
      "136:\t0.07061069458723068 +/- 0.0018236183090122482\n",
      "137:\t0.07089134305715561 +/- 0.0018256914482494189\n",
      "138:\t0.07108217477798462 +/- 0.0018273965004468678\n",
      "139:\t0.0712168887257576 +/- 0.0018280488144273074\n",
      "140:\t0.07148630172014236 +/- 0.0018296042490680473\n",
      "141:\t0.07167714834213257 +/- 0.001832336200669713\n",
      "142:\t0.07186798751354218 +/- 0.001834527703330754\n",
      "143:\t0.07213740795850754 +/- 0.0018352451558751794\n",
      "144:\t0.07229457050561905 +/- 0.0018338965864602098\n",
      "145:\t0.07253032177686691 +/- 0.0018368756313794188\n",
      "146:\t0.0726650282740593 +/- 0.0018351057500648436\n",
      "147:\t0.07268746942281723 +/- 0.0018352499523015063\n",
      "148:\t0.07297934591770172 +/- 0.0018397459057274113\n",
      "149:\t0.07310283184051514 +/- 0.0018417096554996454\n",
      "150:\t0.07321509718894958 +/- 0.0018411008188030065\n",
      "151:\t0.0733722522854805 +/- 0.0018418209016457404\n",
      "152:\t0.07339470833539963 +/- 0.0018411721463041882\n",
      "153:\t0.07367535680532455 +/- 0.0018433053182321585\n",
      "154:\t0.07375393062829971 +/- 0.0018444447015699091\n",
      "155:\t0.07387742400169373 +/- 0.0018458567075911362\n",
      "156:\t0.07428155094385147 +/- 0.0018480407835275417\n",
      "157:\t0.07438258081674576 +/- 0.0018519167601698551\n",
      "158:\t0.07446115463972092 +/- 0.0018499000949845966\n",
      "159:\t0.07467445731163025 +/- 0.0018494634654654311\n",
      "160:\t0.07480917125940323 +/- 0.0018505183698104592\n",
      "161:\t0.07502245903015137 +/- 0.0018524185282530064\n",
      "162:\t0.07522451132535934 +/- 0.0018548941031313352\n",
      "163:\t0.07516840100288391 +/- 0.0018549618719936295\n",
      "164:\t0.07533677667379379 +/- 0.0018555391451105698\n",
      "165:\t0.07541535794734955 +/- 0.0018555976305670704\n",
      "166:\t0.07556130737066269 +/- 0.001854732881317384\n",
      "167:\t0.07566233724355698 +/- 0.0018570011267996529\n",
      "168:\t0.07577459514141083 +/- 0.0018581555183101036\n",
      "169:\t0.0759429782629013 +/- 0.001856883691716362\n",
      "170:\t0.07616749405860901 +/- 0.0018612560211217805\n",
      "171:\t0.07633587718009949 +/- 0.001861012176996265\n",
      "172:\t0.07640323787927628 +/- 0.0018572146451329087\n",
      "173:\t0.07651550322771072 +/- 0.0018583493867677628\n",
      "174:\t0.07660529762506485 +/- 0.0018611805160879914\n",
      "175:\t0.07666143774986267 +/- 0.001859792956368688\n",
      "176:\t0.0769757553935051 +/- 0.0018633017743118596\n",
      "177:\t0.07707679271697998 +/- 0.0018621497036528571\n",
      "178:\t0.07722272723913193 +/- 0.0018635716119735975\n",
      "179:\t0.07724516838788986 +/- 0.0018636898206740376\n",
      "180:\t0.07750336825847626 +/- 0.0018664686534749617\n",
      "181:\t0.07741356641054153 +/- 0.0018641836978622642\n",
      "182:\t0.07754828035831451 +/- 0.001867739087557834\n",
      "183:\t0.07766053825616837 +/- 0.0018675418151847174\n",
      "184:\t0.07771666347980499 +/- 0.001866404752698415\n",
      "185:\t0.07776156812906265 +/- 0.0018671545424396886\n",
      "186:\t0.07785137742757797 +/- 0.0018660587911091683\n",
      "187:\t0.07803098857402802 +/- 0.0018661961855149156\n",
      "188:\t0.07812079042196274 +/- 0.0018658728135464338\n",
      "189:\t0.0780983418226242 +/- 0.001866537660124695\n",
      "190:\t0.07817692309617996 +/- 0.0018686194638739399\n",
      "191:\t0.07824429124593735 +/- 0.0018692171604836262\n",
      "192:\t0.07844634354114532 +/- 0.0018717790710358368\n",
      "193:\t0.07855860143899918 +/- 0.0018707829615941694\n",
      "194:\t0.07868208736181259 +/- 0.0018741062661448958\n",
      "195:\t0.0786147341132164 +/- 0.0018714482723427202\n",
      "196:\t0.07880557328462601 +/- 0.0018712202100070541\n",
      "197:\t0.07900764048099518 +/- 0.0018724609371913866\n",
      "198:\t0.079131118953228 +/- 0.0018737024379928684\n",
      "199:\t0.07920969277620316 +/- 0.0018718819621167174\n",
      "200:\t0.07929951697587967 +/- 0.0018730866387418842\n",
      "201:\t0.0792882889509201 +/- 0.0018716110413909703\n",
      "202:\t0.07936687022447586 +/- 0.0018736656138165534\n",
      "203:\t0.07951280474662781 +/- 0.0018739688717391487\n",
      "204:\t0.07961384207010269 +/- 0.0018725054975391965\n",
      "205:\t0.07971486449241638 +/- 0.0018728494477238543\n",
      "206:\t0.07979345321655273 +/- 0.0018723110101878178\n",
      "207:\t0.07986080646514893 +/- 0.0018721067752603556\n",
      "208:\t0.07996183633804321 +/- 0.0018714103651023958\n",
      "209:\t0.07999551296234131 +/- 0.0018742801752800985\n",
      "210:\t0.08007409423589706 +/- 0.0018739954841690905\n",
      "211:\t0.08014145493507385 +/- 0.0018737870717090213\n",
      "212:\t0.08020880073308945 +/- 0.0018748692073777109\n",
      "213:\t0.08027616143226624 +/- 0.0018767238771318687\n",
      "214:\t0.08027616888284683 +/- 0.0018767238771318687\n",
      "215:\t0.08027616888284683 +/- 0.0018762078744931673\n",
      "216:\t0.08029861003160477 +/- 0.0018778572262558538\n",
      "217:\t0.08050067722797394 +/- 0.0018810846022800452\n",
      "218:\t0.08048945665359497 +/- 0.0018780721370999787\n",
      "219:\t0.08055680990219116 +/- 0.0018781153049369195\n",
      "220:\t0.08070274442434311 +/- 0.0018788934090658643\n",
      "221:\t0.0805792585015297 +/- 0.0018761523287818347\n",
      "222:\t0.080803781747818 +/- 0.0018779222100964099\n",
      "223:\t0.08087112754583359 +/- 0.0018787341986565018\n",
      "224:\t0.080994613468647 +/- 0.0018830065767262076\n",
      "225:\t0.08103951811790466 +/- 0.0018860280158652081\n",
      "226:\t0.08108442276716232 +/- 0.0018851952943655101\n",
      "227:\t0.08110687136650085 +/- 0.0018852923059560545\n",
      "228:\t0.08111809939146042 +/- 0.0018854691548364252\n",
      "229:\t0.08109565079212189 +/- 0.0018853722979693106\n",
      "230:\t0.08114056289196014 +/- 0.0018858228525971666\n",
      "231:\t0.08108442276716232 +/- 0.0018833966344929743\n",
      "232:\t0.08119668066501617 +/- 0.0018861929510414766\n",
      "233:\t0.0812191292643547 +/- 0.001886802870802125\n",
      "234:\t0.08143242448568344 +/- 0.0018880977511869209\n",
      "235:\t0.081443652510643 +/- 0.0018880169855565153\n",
      "236:\t0.08145487308502197 +/- 0.0018869102488624724\n",
      "237:\t0.08154468983411789 +/- 0.0018872900948828661\n",
      "238:\t0.08155591040849686 +/- 0.00188566921223128\n",
      "239:\t0.08160080760717392 +/- 0.0018850880710285926\n",
      "240:\t0.08155591040849686 +/- 0.001885155530444027\n",
      "241:\t0.08165694028139114 +/- 0.0018841677760675739\n",
      "242:\t0.08169062435626984 +/- 0.0018834094765376556\n",
      "243:\t0.08174674957990646 +/- 0.0018822303292784215\n",
      "244:\t0.08178042620420456 +/- 0.0018830140034508426\n",
      "245:\t0.0817355141043663 +/- 0.0018805107330785624\n",
      "246:\t0.08165694773197174 +/- 0.0018800518233854922\n",
      "247:\t0.08181410282850266 +/- 0.001880967631367044\n",
      "248:\t0.08184777945280075 +/- 0.0018838086629867862\n",
      "249:\t0.08189268410205841 +/- 0.001883738109102754\n",
      "250:\t0.08188145607709885 +/- 0.0018833058118396255\n",
      "251:\t0.08188145607709885 +/- 0.0018825343608181663\n",
      "252:\t0.08188146352767944 +/- 0.001885361467329218\n",
      "Early stopiing!\n"
     ]
    }
   ],
   "source": [
    "model, precisions_at = fit_model(\n",
    "    epochs=300,\n",
    "    at=10,\n",
    "    loss=best_params[\"loss\"],\n",
    "    no_components=best_params[\"no_components\"], \n",
    "    learning_rate=best_params[\"learning_rate\"], \n",
    "    max_sampled=best_params[\"max_sampled\"],\n",
    "    user_alpha=best_params[\"user_alpha\"],\n",
    "    item_alpha=best_params[\"item_alpha\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.4: Plot learning curve precision(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save track embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOTIFY_DATA_DIR = \"/Users/n.anokhin/Projects/recsys-course/botify/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases, embeddings = model.get_item_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.item_biases *= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(BOTIFY_DATA_DIR + \"tracks.json\", lines=True)\n",
    "track_meta[\"dataset_index\"] = track_meta[\"track\"].map(lambda t: dataset.mapping()[2].get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tracks = track_meta[pd.notnull(track_meta[\"dataset_index\"])].sort_values(\"dataset_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "writer = tb.SummaryWriter(comment='msd_ligtfm_embeddings', log_dir=DATA_DIR + \"tb\")\n",
    "writer.add_embedding(embeddings, metadata=list(dataset_tracks[[\"artist\", \"title\"]].itertuples(index=False, name=None)), tag=\"lightfm\", metadata_header=[\"artist\", \"title\"])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = dataset_tracks[\"track\"].values\n",
    "users = [user for user, index in sorted(dataset.mapping()[0].items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9750/9750 [00:08<00:00, 1185.70it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(BOTIFY_DATA_DIR + \"recommendations_lfm.json\", \"w\") as rf:\n",
    "    for user_index in tqdm.tqdm(range(dataset.user_features_shape()[0])):\n",
    "        predictions = model.predict(user_index, np.arange(dataset.item_features_shape()[0]), num_threads=30)\n",
    "        top = tracks[np.argsort(predictions)[-100:]]\n",
    "        recommendation = {\n",
    "            \"user\": int(users[user_index]),\n",
    "            \"tracks\": [int(x) for x in top]\n",
    "        }\n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
